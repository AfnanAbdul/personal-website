<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance) | Afn√°n Alabdulwahab</title>
<meta name="keywords" content="LLMs, LLM-as-a-Judge, AI Ethics, Bias Detection, Model Evaluation, Python, Claude, RAGAS, promptfoo, DeepEval, TruLens, UVA, Data Science Capstone, Anthropic, Deloitte">
<meta name="description" content="A comprehensive analysis of evaluation frameworks for LLMs, focusing on bias detection, response quality, and robustness - conducted in collaboration with Deloitte&#39;s Anthropic Alliance.">
<meta name="author" content="Afn√°n Alabdulwahab">
<link rel="canonical" href="https://afnanabdul.dev/projects/project1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.96aa5424d149c81762de590e040b9612c8b4e2598c2d0e71bb0d17c1322e3b46.css" integrity="sha256-lqpUJNFJyBdi3lkOBAuWEsi04lmMLQ5xuw0XwTIuO0Y=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://afnanabdul.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://afnanabdul.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://afnanabdul.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://afnanabdul.dev/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://afnanabdul.dev/projects/project1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)" />
<meta property="og:description" content="A comprehensive analysis of evaluation frameworks for LLMs, focusing on bias detection, response quality, and robustness - conducted in collaboration with Deloitte&#39;s Anthropic Alliance." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://afnanabdul.dev/projects/project1/" />
<meta property="og:image" content="https://afnanabdul.dev/project1.png" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2025-05-23T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-05-23T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://afnanabdul.dev/project1.png" />
<meta name="twitter:title" content="Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)"/>
<meta name="twitter:description" content="A comprehensive analysis of evaluation frameworks for LLMs, focusing on bias detection, response quality, and robustness - conducted in collaboration with Deloitte&#39;s Anthropic Alliance."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://afnanabdul.dev/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)",
      "item": "https://afnanabdul.dev/projects/project1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)",
  "name": "Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)",
  "description": "A comprehensive analysis of evaluation frameworks for LLMs, focusing on bias detection, response quality, and robustness - conducted in collaboration with Deloitte's Anthropic Alliance.",
  "keywords": [
    "LLMs", "LLM-as-a-Judge", "AI Ethics", "Bias Detection", "Model Evaluation", "Python", "Claude", "RAGAS", "promptfoo", "DeepEval", "TruLens", "UVA", "Data Science Capstone", "Anthropic", "Deloitte"
  ],
  "articleBody": " Links Paper (Extended Version) SIEDS Conference Paper (IEEE) Code Presentation Slides LLM Evaluation Framework Leaderboard Overview üèÜ Winner of ‚ÄúMost Innovative Analytical Solution‚Äù Award\nAs part of my UVA capstone project, I collaborated with Deloitte‚Äôs Anthropic Alliance to analyze and compare evaluation frameworks for large language models (LLMs). This award-winning study focused on key metrics such as response accuracy, retrieval effectiveness, bias detection, toxicity, hallucination, and tone identification. I led the bias detection evaluation, implementing Counterfactual Data Testing with the WinoBias dataset to measure LLM response consistency across sensitive attributes. Additionally, I developed and applied custom bias detection methods using promptfoo, DeepEval, and RAGAS, conducting comparative analyses on 1,500+ sentence pairs from the CrowS-Pairs dataset. By integrating counterfactual data testing with contextual sensitivity analysis, our research aimed to enhance bias evaluation in LLMs and contribute to more ethical AI assessment methodologies.\nPublications: This research was presented at the UVA 2025 Systems and Information Engineering Design Symposium (SIEDS), where we published a condensed 6-page version of our findings in the IEEE conference proceedings.\nRelated material üèõÔ∏è UVA Master‚Äôs in Data Science Students Showcase Real-World Solutions in 2025 Capstone Presentations Deloitte and Anthropic Collaborate to Bring Safe, Reliable and Trusted AI to Commercial and Government Organizations Deloitte Collaborates With Anthropic to Advance Enterprise AI Capabilities Through AI Training and Certification Program ",
  "wordCount" : "219",
  "inLanguage": "en",
  "image":"https://afnanabdul.dev/project1.png","datePublished": "2025-05-23T00:00:00Z",
  "dateModified": "2025-05-23T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Afn√°n Alabdulwahab"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://afnanabdul.dev/projects/project1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Afn√°n Alabdulwahab",
    "logo": {
      "@type": "ImageObject",
      "url": "https://afnanabdul.dev/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://afnanabdul.dev/" accesskey="h" title="Afn√°n">
                <img src="https://afnanabdul.dev/apple-touch-icon.png" alt="" aria-label="logo"
                    height="64"
                    width="64">Afn√°n</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://afnanabdul.dev/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://afnanabdul.dev/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://afnanabdul.dev/courses/" title="Courses">
                    <span>Courses</span>
                </a>
            </li>
            <li>
                <a href="https://afnanabdul.dev/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Comparative Study of LLM Evaluation Frameworks (Deloitte-Anthropic Alliance)
    </h1>
    <div class="post-meta"><span title='2025-05-23 00:00:00 +0000 UTC'>May 2025</span>&nbsp;&middot;&nbsp;Afn√°n Alabdulwahab

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="links">Links</h5>
<ul>
<li><a href="LLM_as_a_judge_Deloitte.pdf">Paper (Extended Version)</a></li>
<li><a href="https://ieeexplore.ieee.org/document/11021089" target="_blank">SIEDS Conference Paper (IEEE)</a></li>
<li><a href="https://github.com/AfnanAbdul/LLM-eval-framework-comparison" target="_blank">Code</a></li>
<li><a href="1003am_deloitte_anthropic_llm.pdf">Presentation Slides</a></li>
<li><a href="https://llm-evaluation-framework-leaderboard.vercel.app" target="_blank">LLM Evaluation Framework Leaderboard</a></li>
</ul>
<hr>
<h5 id="overview">Overview</h5>
<p>üèÜ Winner of <a href="https://bit.ly/3RTDgCo" target="_blank">&ldquo;Most Innovative Analytical Solution&rdquo; Award</a></p>
<p>As part of my UVA capstone project, I collaborated with Deloitte&rsquo;s Anthropic Alliance to analyze and compare evaluation frameworks for large language models (LLMs). This award-winning study focused on key metrics such as response accuracy, retrieval effectiveness, bias detection, toxicity, hallucination, and tone identification. I led the bias detection evaluation, implementing Counterfactual Data Testing with the WinoBias dataset to measure LLM response consistency across sensitive attributes. Additionally, I developed and applied custom bias detection methods using promptfoo, DeepEval, and RAGAS, conducting comparative analyses on 1,500+ sentence pairs from the CrowS-Pairs dataset. By integrating counterfactual data testing with contextual sensitivity analysis, our research aimed to enhance bias evaluation in LLMs and contribute to more ethical AI assessment methodologies.</p>
<p><strong>Publications:</strong> This research was presented at the UVA 2025 Systems and Information Engineering Design Symposium (SIEDS), where we published a condensed 6-page version of our findings in the IEEE conference proceedings.</p>
<hr>
<h4 id="related-material">Related material</h4>
<ul>
<li><a href="https://bit.ly/3RTDgCo" target="_blank">üèõÔ∏è UVA Master‚Äôs in Data Science Students Showcase Real-World Solutions in 2025 Capstone Presentations</a></li>
<li><a href="https://www.prnewswire.com/news-releases/deloitte-and-anthropic-collaborate-to-bring-safe-reliable-and-trusted-ai-to-commercial-and-government-organizations-302210769.html?tc" target="_blank">Deloitte and Anthropic Collaborate to Bring Safe, Reliable and Trusted AI to Commercial and Government Organizations</a></li>
<li><a href="https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloitte-and-anthropic-launch-certification-program.html" target="_blank">Deloitte Collaborates With Anthropic to Advance Enterprise AI Capabilities Through AI Training and Certification Program</a></li>
</ul>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://afnanabdul.dev/tags/llms/">LLMs</a></li>
      <li><a href="https://afnanabdul.dev/tags/llm-as-a-judge/">LLM-as-a-Judge</a></li>
      <li><a href="https://afnanabdul.dev/tags/ai-ethics/">AI Ethics</a></li>
      <li><a href="https://afnanabdul.dev/tags/bias-detection/">Bias Detection</a></li>
      <li><a href="https://afnanabdul.dev/tags/model-evaluation/">Model Evaluation</a></li>
      <li><a href="https://afnanabdul.dev/tags/python/">Python</a></li>
      <li><a href="https://afnanabdul.dev/tags/claude/">Claude</a></li>
      <li><a href="https://afnanabdul.dev/tags/ragas/">RAGAS</a></li>
      <li><a href="https://afnanabdul.dev/tags/promptfoo/">Promptfoo</a></li>
      <li><a href="https://afnanabdul.dev/tags/deepeval/">DeepEval</a></li>
      <li><a href="https://afnanabdul.dev/tags/trulens/">TruLens</a></li>
      <li><a href="https://afnanabdul.dev/tags/uva/">UVA</a></li>
      <li><a href="https://afnanabdul.dev/tags/data-science-capstone/">Data Science Capstone</a></li>
      <li><a href="https://afnanabdul.dev/tags/anthropic/">Anthropic</a></li>
      <li><a href="https://afnanabdul.dev/tags/deloitte/">Deloitte</a></li>
    </ul>
  </footer>
</article>
    </main>
    

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
